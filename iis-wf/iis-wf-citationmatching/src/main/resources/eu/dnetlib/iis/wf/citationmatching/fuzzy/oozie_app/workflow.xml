<?xml version="1.0"?>
<!-- TODO MiconCodeReview: From external project user viewpoint, it would be more appropriate to call this a 'main' instead of 'chain' workflow. -->
<!-- TODO MiconCodeReview: E.g.: the main workflow in icm-iis-collapsers is called just 'main'. -->
<!-- TODO MiconCodeReview: Also, 'citationmatching_' prefix is unnecessary (it's encoded in the path eu.dnetlib.iis.citationmatching). -->
<!-- TODO MiconCodeReview: In case of renaming, the package should be renamed accordingly ('chain' -> 'main'). -->
<workflow-app xmlns="uri:oozie:workflow:0.4" name="citationmatching_chain">

	<parameters>
        <property>
            <name>input_metadata</name>
            <description>input directory holding eu.dnetlib.iis.transformers.metadatamerger.schemas.ExtractedDocumentMetadataMergedWithOriginal avro datastore</description>
        </property>
        <property>
            <name>input_person</name>
            <description>input directory holding eu.dnetlib.iis.importer.schemas.Person avro datastore</description>
        </property>
        <property>
            <name>output_citations</name>
            <description>output directory holding eu.dnetlib.iis.common.citations.schemas.Citation avro datastore</description>
        </property>
        <property>
            <name>output_report_root_path</name>
            <description>base directory for storing reports</description>
        </property>
        <property>
            <name>output_report_relative_path</name>
            <value>citationmatching_fuzzy</value>
            <description>directory for storing report (relative to output_report_root_path)</description>
        </property>
        
        <property>
            <name>sparkDriverMemory</name>
            <description>memory for driver process</description>
        </property>
        <property>
            <name>sparkDriverOverhead</name>
            <description>The amount of off heap memory (in megabytes) to be allocated for the driver</description>
        </property>
        
        <property>
            <name>sparkExecutorMemory</name>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>sparkExecutorOverhead</name>
            <description>The amount of off heap memory (in megabytes) to be allocated for the executor</description>
        </property>
        <property>
            <name>sparkExecutorCores</name>
            <description>number of cores used by single executor</description>
        </property>
        
        <property>
            <name>numberOfPartitions</name>
            <description>number of partitions used for rdds with citations and documents read from input files</description>
        </property>
        
    </parameters>

    <global>
        <job-tracker>${jobTracker}</job-tracker>
        <name-node>${nameNode}</name-node>
        <configuration>
            <property>
                <name>mapreduce.job.queuename</name>
                <value>${queueName}</value>
            </property>
            <property>
                <name>oozie.launcher.mapred.job.queue.name</name>
                <value>${oozieLauncherQueueName}</value>
            </property>
        </configuration>
    </global>
    
    
    <start to="citation-matching-input-transformer" />


    <action name="citation-matching-input-transformer">
    
        <spark xmlns="uri:oozie:spark-action:0.2">

            <prepare>
                <delete path="${workingDir}/documents_with_authors" />
            </prepare>
            
            <master>yarn-cluster</master>
            <mode>cluster</mode>
            <name>citation-matching-input-transformer</name>

            <class>eu.dnetlib.iis.wf.citationmatching.input.CitationMatchingInputTransformerJob</class>

            <jar>${oozieTopWfApplicationPath}/lib/${projectUberJarName}</jar>
            
            <spark-opts>--executor-memory ${sparkExecutorMemory} --executor-cores ${sparkExecutorCores}</spark-opts>
        
            <arg>-inputMetadata = ${input_metadata}</arg>
            <arg>-inputPerson = ${input_person}</arg>
            <arg>-output = ${workingDir}/documents_with_authors</arg>
            
        </spark>
        <ok to="citation-matching"/>
        <error to="fail"/>
    
    </action>
    
    <action name="citation-matching">
    
        <spark xmlns="uri:oozie:spark-action:0.2">
           
            <prepare>
                <delete path="${workingDir}/matched_citations" />
            </prepare>
            
            <master>yarn-cluster</master>
            <mode>cluster</mode>
            <name>citation-matching</name>

            <class>eu.dnetlib.iis.wf.citationmatching.IisCitationMatchingJob</class>

            <jar>${oozieTopWfApplicationPath}/lib/${projectUberJarName}</jar>
            
            <spark-opts>--executor-cores ${sparkExecutorCores} --executor-memory ${sparkExecutorMemory} --driver-memory=${sparkDriverMemory} --conf spark.yarn.driver.memoryOverhead=${sparkDriverOverhead}  --conf spark.yarn.executor.memoryOverhead=${sparkExecutorOverhead}</spark-opts>
        
            <arg>-fullDocumentPath = ${workingDir}/documents_with_authors</arg>
            
            <arg>-outputDirPath = ${workingDir}/matched_citations</arg>
            <arg>-outputReportPath=${output_report_root_path}/${output_report_relative_path}</arg>
            
            <arg>-numberOfPartitions = ${numberOfPartitions}</arg>
            
        </spark>
        <ok to="citation-matching-output-transformer"/>
        <error to="fail"/>
    
    </action>
    
        <action name="citation-matching-output-transformer">
    
        <spark xmlns="uri:oozie:spark-action:0.2">
           
            <prepare>
                <delete path="${output_citations}" />
            </prepare>
            
            <master>yarn-cluster</master>
            <mode>cluster</mode>
            <name>citation-matching-output-transformer</name>

            <class>eu.dnetlib.iis.wf.citationmatching.output.CitationMatchingOutputTransformerJob</class>

            <jar>${oozieTopWfApplicationPath}/lib/${projectUberJarName}</jar>
            
            <spark-opts>--executor-memory ${sparkExecutorMemory} --executor-cores ${sparkExecutorCores}</spark-opts>
        
            <arg>-input = ${workingDir}/matched_citations</arg>
            <arg>-output = ${output_citations}</arg>
            
        </spark>
        <ok to="end"/>
        <error to="fail"/>
    
    </action>
    
    
    <kill name="fail">
        <message>Unfortunately, the process failed -- error message:
            [${wf:errorMessage(wf:lastErrorNode())}]
        </message>
    </kill>
    <end name="end" />
</workflow-app>
