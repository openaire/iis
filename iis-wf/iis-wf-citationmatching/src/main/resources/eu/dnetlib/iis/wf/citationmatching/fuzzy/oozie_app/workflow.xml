<?xml version="1.0"?>
<!-- TODO MiconCodeReview: From external project user viewpoint, it would be more appropriate to call this a 'main' instead of 'chain' workflow. -->
<!-- TODO MiconCodeReview: E.g.: the main workflow in icm-iis-collapsers is called just 'main'. -->
<!-- TODO MiconCodeReview: Also, 'citationmatching_' prefix is unnecessary (it's encoded in the path eu.dnetlib.iis.citationmatching). -->
<!-- TODO MiconCodeReview: In case of renaming, the package should be renamed accordingly ('chain' -> 'main'). -->
<workflow-app xmlns="uri:oozie:workflow:0.4" name="citationmatching_chain">

	<parameters>
        <property>
            <name>input_metadata</name>
            <description>input directory holding eu.dnetlib.iis.transformers.metadatamerger.schemas.ExtractedDocumentMetadataMergedWithOriginal avro datastore</description>
        </property>
        <property>
            <name>input_matched_citations</name>
            <description>input directory holding already matched citations to be excluded from processing as eu.dnetlib.iis.common.citations.schemas.Citation avro datastore. </description>
        </property>
        <property>
            <name>output_citations</name>
            <description>output directory holding eu.dnetlib.iis.common.citations.schemas.Citation avro datastore</description>
        </property>
        <property>
            <name>output_report_root_path</name>
            <description>base directory for storing reports</description>
        </property>
        <property>
            <name>output_report_relative_path</name>
            <value>citationmatching_fuzzy</value>
            <description>directory for storing report (relative to output_report_root_path)</description>
        </property>

        <property>
            <name>citationMatchingSparkNetworkTimeout</name>
            <value>1200s</value>
            <description>spark network timeout for citation matching jobs</description>
        </property>
        <property>
            <name>citationMatchingSparkShuffleRegistrationTimeout</name>
            <value>30000</value>
            <description>spark shuffle service registration timeout for citation matching jobs</description>
        </property>
        
        <property>
            <name>sparkDriverMemory</name>
            <description>memory for driver process</description>
        </property>

        <property>
            <name>sparkExecutorMemory</name>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>sparkExecutorOverhead</name>
            <description>The amount of off heap memory (in megabytes) to be allocated for the executor</description>
        </property>
        <property>
            <name>sparkExecutorCores</name>
            <description>number of cores used by single executor</description>
        </property>
        <property>
            <name>oozieActionShareLibForSpark2</name>
            <description>oozie action sharelib for spark 2.*</description>
        </property>
        <property>
            <name>spark2ExtraListeners</name>
            <value>com.cloudera.spark.lineage.NavigatorAppListener</value>
            <description>spark 2.* extra listeners classname</description>
        </property>
        <property>
            <name>spark2SqlQueryExecutionListeners</name>
            <value>com.cloudera.spark.lineage.NavigatorQueryListener</value>
            <description>spark 2.* sql query execution listeners classname</description>
        </property>
        <property>
            <name>spark2YarnHistoryServerAddress</name>
            <description>spark 2.* yarn history server address</description>
        </property>
        <property>
            <name>spark2EventLogDir</name>
            <description>spark 2.* event log dir location</description>
        </property>
        
        <property>
            <name>numberOfPartitions</name>
            <description>number of partitions used for rdds with citations and documents read from input files</description>
        </property>
        <property>
            <name>cacheRootDir</name>
            <description>citationmatching cache root directory</description>
        </property>
        <property>
            <name>cacheOlderThanXYears</name>
            <value>2</value>
            <description>Indicates the number of years, to be substracted from the current year, to indicate the threshold before which given publication is considered as eligible for caching matched output</description>
        </property>
        <property>
            <name>citationmatchingCacheLockManagerFactoryClassName</name>
            <value>eu.dnetlib.iis.common.lock.ZookeeperLockManagerFactory</value>
            <description>lock manager factory class name, to be used for synchronizing access to cache directory</description>
        </property>
        <property>
            <name>citationmatchingNumberOfEmittedFilesInCache</name>
            <value>1000</value>
            <description>number of files created by citation matching caching module in cache</description>
        </property>
        <property>
            <name>citationmatchingNumberOfEmittedFiles</name>
            <value>1000</value>
            <description>number of files generated as citation matching final outcome</description>
        </property>
    </parameters>

    <global>
        <job-tracker>${jobTracker}</job-tracker>
        <name-node>${nameNode}</name-node>
        <configuration>
            <property>
                <name>mapreduce.job.queuename</name>
                <value>${queueName}</value>
            </property>
            <property>
                <name>oozie.launcher.mapred.job.queue.name</name>
                <value>${oozieLauncherQueueName}</value>
            </property>
            <property>
                <name>oozie.action.sharelib.for.spark</name>
                <value>${oozieActionShareLibForSpark2}</value>
            </property>
        </configuration>
    </global>

    <start to="citation-matching-input-transformer"/>

    <action name="citation-matching-input-transformer">
        <spark xmlns="uri:oozie:spark-action:0.2">
            <master>yarn-cluster</master>
            <mode>cluster</mode>
            <name>citation-matching-input-transformer</name>

            <class>eu.dnetlib.iis.wf.citationmatching.input.CitationMatchingInputTransformerJob</class>

            <jar>${oozieTopWfApplicationPath}/lib/iis-wf-citationmatching-${projectVersion}.jar</jar>

            <spark-opts>
                --executor-memory=${sparkExecutorMemory}
                --executor-cores=${sparkExecutorCores}
                --driver-memory=${sparkDriverMemory}
                --conf spark.yarn.executor.memoryOverhead=${sparkExecutorOverhead}
                --conf spark.extraListeners=${spark2ExtraListeners}
                --conf spark.sql.queryExecutionListeners=${spark2SqlQueryExecutionListeners}
                --conf spark.yarn.historyServer.address=${spark2YarnHistoryServerAddress}
                --conf spark.eventLog.dir="${nameNode}${spark2EventLogDir}"
                --conf spark.network.timeout=${citationMatchingSparkNetworkTimeout}
                --conf spark.shuffle.registration.timeout=${citationMatchingSparkShuffleRegistrationTimeout}
            </spark-opts>

            <arg>-inputMetadata = ${input_metadata}</arg>
            <arg>-inputMatchedCitations = ${input_matched_citations}</arg>
            <arg>-cacheRootDir=${cacheRootDir}</arg>
            <arg>-output = ${workingDir}/documents_with_authors</arg>
        </spark>
        <ok to="citation-matching"/>
        <error to="fail"/>
    </action>

    <action name="citation-matching">
        <spark xmlns="uri:oozie:spark-action:0.2">
            <master>yarn-cluster</master>
            <mode>cluster</mode>
            <name>citation-matching</name>

            <class>eu.dnetlib.iis.wf.citationmatching.IisCitationMatchingJob</class>

            <jar>${oozieTopWfApplicationPath}/lib/iis-wf-citationmatching-${projectVersion}.jar</jar>

            <spark-opts>
                --executor-cores=${sparkExecutorCores}
                --executor-memory=${sparkExecutorMemory}
                --driver-memory=${sparkDriverMemory}
                --conf spark.yarn.executor.memoryOverhead=${sparkExecutorOverhead}
                --conf spark.extraListeners=${spark2ExtraListeners}
                --conf spark.sql.queryExecutionListeners=${spark2SqlQueryExecutionListeners}
                --conf spark.yarn.historyServer.address=${spark2YarnHistoryServerAddress}
                --conf spark.eventLog.dir="${nameNode}${spark2EventLogDir}"
                --conf spark.network.timeout=${citationMatchingSparkNetworkTimeout}
                --conf spark.shuffle.registration.timeout=${citationMatchingSparkShuffleRegistrationTimeout}
            </spark-opts>

            <arg>-fullDocumentPath = ${workingDir}/documents_with_authors</arg>

            <arg>-outputDirPath = ${workingDir}/matched_citations</arg>
            <arg>-outputReportPath=${output_report_root_path}/${output_report_relative_path}</arg>

            <arg>-numberOfPartitions = ${numberOfPartitions}</arg>
        </spark>
        <ok to="citation-matching-output-transformer"/>
        <error to="fail"/>
    </action>

    <action name="citation-matching-output-transformer">
        <spark xmlns="uri:oozie:spark-action:0.2">
            <master>yarn-cluster</master>
            <mode>cluster</mode>
            <name>citation-matching-output-transformer</name>

            <class>eu.dnetlib.iis.wf.citationmatching.output.CitationMatchingOutputTransformerJob</class>

            <jar>${oozieTopWfApplicationPath}/lib/iis-wf-citationmatching-${projectVersion}.jar</jar>

            <spark-opts>
                --executor-memory=${sparkExecutorMemory}
                --executor-cores=${sparkExecutorCores}
                --driver-memory=${sparkDriverMemory}
                --conf spark.extraListeners=${spark2ExtraListeners}
                --conf spark.sql.queryExecutionListeners=${spark2SqlQueryExecutionListeners}
                --conf spark.yarn.historyServer.address=${spark2YarnHistoryServerAddress}
                --conf spark.eventLog.dir="${nameNode}${spark2EventLogDir}"
                --conf spark.network.timeout=${citationMatchingSparkNetworkTimeout}
                --conf spark.shuffle.registration.timeout=${citationMatchingSparkShuffleRegistrationTimeout}
            </spark-opts>

            <arg>-inputMetadata=${input_metadata}</arg>
            <arg>-inputMatchedCitations=${workingDir}/matched_citations</arg>
            <arg>-cacheRootDir=${cacheRootDir}</arg>
            <arg>-cacheOlderThanXYears=${cacheOlderThanXYears}</arg>
            <arg>-lockManagerFactoryClassName=${citationmatchingCacheLockManagerFactoryClassName}</arg>
            <arg>-numberOfEmittedFilesInCache=${citationmatchingNumberOfEmittedFilesInCache}</arg>
            <arg>-numberOfEmittedFiles=${citationmatchingNumberOfEmittedFiles}</arg>
            <arg>-output=${output_citations}</arg>
        </spark>
        <ok to="end"/>
        <error to="fail"/>
    </action>

    <kill name="fail">
        <message>Unfortunately, the process failed -- error message:
            [${wf:errorMessage(wf:lastErrorNode())}]
        </message>
    </kill>

    <end name="end"/>

</workflow-app>
