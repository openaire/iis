package eu.dnetlib.iis.wf.affro;

import static eu.dnetlib.iis.common.report.ReportEntryFactory.createCounterReportEntry;

import java.io.IOException;
import java.util.List;

import org.apache.commons.lang3.StringUtils;
import org.apache.commons.lang3.SystemUtils;
import org.apache.spark.SparkConf;
import org.apache.spark.SparkFiles;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;

import com.beust.jcommander.JCommander;
import com.beust.jcommander.Parameter;
import com.beust.jcommander.Parameters;
import com.google.common.collect.ImmutableList;

import eu.dnetlib.iis.affro.schemas.AffroResult;
import eu.dnetlib.iis.common.WorkflowRuntimeParameters;
import eu.dnetlib.iis.common.java.io.HdfsUtils;
import eu.dnetlib.iis.common.schemas.ReportEntry;
import eu.dnetlib.iis.common.spark.JavaSparkContextFactory;
import eu.dnetlib.iis.common.utils.AvroGsonFactory;
import eu.dnetlib.iis.metadataextraction.schemas.DocumentTextWithDOI;
import pl.edu.icm.sparkutils.avro.SparkAvroLoader;
import pl.edu.icm.sparkutils.avro.SparkAvroSaver;

/**
 * Spark job responsible for running affro shell script.
 * 
 * Processes {@link DocumentTextWithDOI} input records and calculates provides output generated by the script.
 * 
 * @author mhorst
 */
public class AffroJob {
    
    private static final String COUNTER_OUTPUT_VALID = "affro.output.valid";
    
    private static SparkAvroLoader avroLoader = new SparkAvroLoader();
    private static SparkAvroSaver avroSaver = new SparkAvroSaver();

    //------------------------ LOGIC --------------------------
    
    public static void main(String[] args) throws IOException {
        AffroJobParameters params = new AffroJobParameters();
        JCommander jcommander = new JCommander(params);
        jcommander.parse(args);

        try (JavaSparkContext sc = JavaSparkContextFactory.withConfAndKryo(new SparkConf())) {
            HdfsUtils.remove(sc.hadoopConfiguration(), params.outputAvroPath);
            HdfsUtils.remove(sc.hadoopConfiguration(), params.outputReportPath);

            sc.sc().addFile(params.scriptDirPath, true);

            JavaRDD<DocumentTextWithDOI> inputRecords = avroLoader.loadJavaRDD(sc, params.inputAvroPath,
                    DocumentTextWithDOI.class);

            JavaRDD<DocumentTextWithDOI> repartRecords = shouldRepartition(params.numberOfPartitions)
                    ? inputRecords.repartition(Integer.parseInt(params.numberOfPartitions))
                    : inputRecords;

            String scriptsDirOnWorkerNode = (sc.isLocal()) ? getScriptPath() : "scripts";
            
            JavaRDD<String> stringDocumentClasses = repartRecords
                    .pipe("bash " + scriptsDirOnWorkerNode + "/run_affro.sh" + " " + scriptsDirOnWorkerNode);

            JavaRDD<AffroResult> outputRecords = stringDocumentClasses
                    .map(recordString -> AvroGsonFactory.create().fromJson(recordString, AffroResult.class)
            );

            outputRecords.cache();
            
            avroSaver.saveJavaRDD(outputRecords, AffroResult.SCHEMA$, params.outputAvroPath);

            List<ReportEntry> reportEntries = createReportEntries(outputRecords.count());
            
            avroSaver.saveJavaRDD(sc.parallelize(reportEntries, 1), ReportEntry.SCHEMA$, params.outputReportPath);
        }
        
    }

    //------------------------ PRIVATE --------------------------
    
    private static ImmutableList<ReportEntry> createReportEntries(long outputCount) {

        return ImmutableList.of(createCounterReportEntry(COUNTER_OUTPUT_VALID, outputCount)
                );
    }
    
    /**
     * Checks whether partitioning should be perfomed based on the parameter value.
     */
    private static boolean shouldRepartition(String numberOfPartitions) {
        return (StringUtils.isNotBlank(numberOfPartitions) && !WorkflowRuntimeParameters.UNDEFINED_NONEMPTY_VALUE.equals(numberOfPartitions));
    }
    
    private static String getScriptPath() {
        String path = SparkFiles.get("scripts");

        if (SystemUtils.IS_OS_WINDOWS) {
            return path.replace("\\", "/");
        }
        
        return path;
    }

    @Parameters(separators = "=")
    private static class AffroJobParameters {
        
        @Parameter(names = "-inputAvroPath", required = true)
        private String inputAvroPath;
        
        @Parameter(names = "-outputAvroPath", required = true)
        private String outputAvroPath;

        @Parameter(names = "-scriptDirPath", required = true, description = "path to directory with scripts")
        private String scriptDirPath;
        
        @Parameter(names = "-numberOfPartitions", required = false, description = "number of partitions the data should be sliced into")
        private String numberOfPartitions;
        
        @Parameter(names = "-outputReportPath", required = true)
        private String outputReportPath;
        
    }
}
