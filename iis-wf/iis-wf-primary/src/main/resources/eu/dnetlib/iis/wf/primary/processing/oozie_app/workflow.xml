<workflow-app xmlns="uri:oozie:workflow:0.4" name="primary_processing">

    <parameters>
        <property>
            <name>remove_sideproducts</name>
            <value>false</value>
            <description>flag indicating inference side products will be erased</description>
        </property>
        <!-- processing modes -->
        <property>
            <name>active_referenceextraction_project</name>
            <value>true</value>
            <description>flag indicating project reference extraction should be enabled</description>
        </property>
        <property>
            <name>active_referenceextraction_dataset</name>
            <value>true</value>
            <description>flag indicating dataset reference extraction should be enabled</description>
        </property>
        <property>
            <!-- currently disabled by default -->
            <name>active_referenceextraction_researchinitiative</name>
            <value>false</value>
            <description>flag indicating researchinitiative reference extraction should be enabled</description>
        </property>
        <property>
            <!-- currently disabled by default -->
            <name>active_referenceextraction_community</name>
            <value>false</value>
            <description>flag indicating community reference extraction should be enabled</description>
        </property>
        <property>
            <!-- currently disabled by default -->
            <name>active_referenceextraction_pdb</name>
            <value>false</value>
            <description>flag indicating protein databank reference extraction should be enabled</description>
        </property>
        <property>
            <!-- currently disabled by default -->
            <name>active_referenceextraction_software_url</name>
            <value>false</value>
            <description>flag indicating software url reference extraction should be enabled</description>
        </property>
        <property>
            <name>active_referenceextraction_covid19</name>
            <value>false</value>
            <description>flag indicating covid19 reference extraction should be enabled</description>
        </property>
        <property>
            <name>active_referenceextraction_eoscservice</name>
            <value>false</value>
            <description>flag indicating EOSC service reference extraction should be enabled</description>
        </property>
        <property>
            <name>active_documentsclassification</name>
            <value>true</value>
            <description>flag indicating documents classification should be enabled</description>
        </property>
        <property>
            <name>active_documentssimilarity</name>
            <value>true</value>
            <description>flag indicating documents similarity should be enabled</description>
        </property>
        <property>
            <name>active_citationmatching</name>
            <value>false</value>
            <description>flag indicating citation matching should be enabled</description>
        </property>
        <property>
            <name>active_document_affiliation</name>
            <value>true</value>
            <description>flag indicating affiliation matching should be enabled</description>
        </property>
        <property>
            <name>active_referenceextraction_patent</name>
            <description>flag indicating patent reference extraction should be enabled</description>
        </property>
        <!-- input ports -->
        <property>
            <name>input_document_metadata</name>
            <description>input document metadata directory</description>
        </property>
        <property>
            <name>input_document_to_project</name>
            <description>input document to project relation directory</description>
        </property>
        <property>
            <name>input_project_to_organization</name>
            <description>input project to organization relation directory</description>
        </property>
        <property>
            <name>input_document_text</name>
            <description>input document text directory</description>
        </property>
        <property>
            <name>input_document_text_wos</name>
            <description>input document text directory holding WOS records</description>
        </property>
        <property>
            <name>input_project</name>
            <description>input project directory</description>
        </property>
        <property>
            <name>input_organizations</name>
            <description>input organization directory</description>
        </property>
        <property>
            <name>input_dataset</name>
            <description>input dataset directory</description>
        </property>
        <property>
            <name>input_service</name>
            <description>input service directory</description>
        </property>
        <property>
            <name>input_extracted_document_metadata</name>
            <description>input extracted document metadata directory</description>
        </property>
        <property>
            <name>input_concept</name>
            <description>input concept directory</description>
        </property>
        <property>
            <name>input_patent</name>
            <description>input patent</description>
        </property>
        <!-- project reference extraction related -->
        <property>
            <name>referenceextraction_project_fundingclass_blacklist_regex</name>
            <value>a^</value>
            <description>regexp matching funding class, describes projects which
                should be ignored by reference extraction algorithm.
                Set to 'a^' by default to guarantee nothing will be matched.
            </description>
        </property>
        <!-- software reference extraction related -->
        <property>
            <name>software_webcrawl_cache_location</name>
            <description>software reference extraction HDFS cache location</description>
        </property>
        <!-- document similarity related -->
        <property>
            <name>ds_parallel</name>
            <value>80</value>
            <description>document similarity pig parallel</description>
        </property>
        <property>
            <name>ds_mapredChildJavaOpts</name>
            <value>-Xmx12g</value>
            <description>mapred child java opts</description>
        </property>
        <property>
            <name>ds_sample</name>
            <value>1.0</value>
            <description>sample rate</description>
        </property>
        <property>
            <name>ds_removal_rate</name>
            <value>0.99</value>
            <description>document similarity removal rate</description>
        </property>
        <property>
            <name>ds_removal_least_used</name>
            <value>20</value>
            <description>document similarity least used removal</description>
        </property>
        <property>
            <name>ds_tfidfTopnTermPerDocument</name>
            <value>20</value>
        </property>
        <property>
            <name>ds_similarityTopnDocumentPerDocument</name>
            <value>20</value>
        </property>
        <!-- generic spark configuration -->
        <property>
            <name>sparkDriverMemory</name>
            <description>memory for driver process</description>
        </property>
        <property>
            <name>sparkExecutorMemory</name>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>sparkExecutorCores</name>
            <description>number of cores used by single executor</description>
        </property>
        <!-- specific spark configuration -->
        <property>
            <name>projectReferenceExtractionSparkDriverMemory</name>
            <value>${sparkDriverMemory}</value>
            <description>memory for driver process</description>
        </property>
        <property>
            <name>projectReferenceExtractionSparkExecutorMemory</name>
            <value>${sparkExecutorMemory}</value>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>projectReferenceExtractionSparkExecutorCores</name>
            <value>${sparkExecutorCores}</value>
            <description>number of cores used by single executor</description>
        </property>
        <!-- spark related: research initatives input transformers -->
        <property>
            <name>researchInitiativeReferenceExtractionSparkDriverMemory</name>
            <value>${sparkDriverMemory}</value>
            <description>memory for driver process</description>
        </property>
        <property>
            <name>researchInitiativeReferenceExtractionSparkExecutorMemory</name>
            <value>${sparkExecutorMemory}</value>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>researchInitiativeReferenceExtractionSparkExecutorCores</name>
            <value>${sparkExecutorCores}</value>
            <description>number of cores used by single executor</description>
        </property>
        <property>
            <name>researchInitiativeReferenceExtractionSparkExecutorOverhead</name>
            <value>2048</value>
            <description>The amount of off heap memory (in megabytes) to be allocated for the executor</description>
        </property>
        <!-- spark related: documents classification -->
        <property>
            <name>documentsclassificationSparkDriverMemory</name>
            <value>${sparkDriverMemory}</value>
            <description>memory for driver process</description>
        </property>
        <property>
            <name>documentsclassificationSparkExecutorMemory</name>
            <value>${sparkExecutorMemory}</value>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>documentsclassificationSparkExecutorCores</name>
            <value>${sparkExecutorCores}</value>
            <description>number of cores used by single executor</description>
        </property>
        <property>
            <name>documentsclassificationNumberOfPartitions</name>
            <value>$UNDEFINED$</value>
            <description>number of cores used by single executor</description>
        </property>
        <!-- spark related: affiliation matching -->
        <property>
            <name>affiliationmatchingSparkExecutorMemory</name>
            <value>${sparkExecutorMemory}</value>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>affiliationmatchingSparkExecutorCores</name>
            <value>${sparkExecutorCores}</value>
            <description>number of cores used by single executor</description>
        </property>
        <property>
            <name>affiliationmatchingSparkDriverMemory</name>
            <value>${sparkDriverMemory}</value>
            <description>memory for driver process</description>
        </property>
        <property>
            <name>affiliationmatchingSparkDriverOverhead</name>
            <value>513</value>
            <description>The amount of off heap memory (in megabytes) to be allocated for the driver</description>
        </property>
        <property>
            <name>affiliationmatchingProjectFundingclassWhitelistRegex</name>
            <value>a^</value>
            <description>regex accepting project references by funding class, limiting set of projects allowed to be used in matching publications with organizations. 
            Nothing is accepted by default which means project based version of mining algorithm will return zero results, only regular affiliation matching algorithm will produce results.</description>
        </property>
        <!-- spark related: direct citation matching -->
        <property>
            <name>citationmatchingDirectSparkExecutorMemory</name>
            <value>${sparkExecutorMemory}</value>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>citationmatchingDirectSparkExecutorOverhead</name>
            <value>2048</value>
            <description>The amount of off heap memory (in megabytes) to be allocated for the executor</description>
        </property>
        <property>
            <name>citationmatchingDirectSparkExecutorCores</name>
            <value>${sparkExecutorCores}</value>
            <description>number of cores used by single executor</description>
        </property>
        <property>
            <name>citationmatchingDirectSparkDriverMemory</name>
            <value>${sparkDriverMemory}</value>
            <description>memory for driver process</description>
        </property>
        <property>
            <name>citationmatchingDirectPmcIdsMappingCSV</name>
            <description>CSV dump HDFS location. Contains entries with mappings between different kinds of PMC identifiers for each publication.</description>
        </property>
        <!-- spark related: fuzzy citation matching -->
        <property>
            <name>citationmatchingFuzzySparkDriverMemory</name>
            <value>${sparkDriverMemory}</value>
            <description>memory for driver process</description>
        </property>
        <property>
            <name>citationmatchingFuzzySparkDriverOverhead</name>
            <value>513</value>
            <description>The amount of off heap memory (in megabytes) to be allocated for the driver</description>
        </property>
        <property>
            <name>citationmatchingFuzzySparkExecutorMemory</name>
            <value>${sparkExecutorMemory}</value>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>citationmatchingFuzzySparkExecutorOverhead</name>
            <value>4096</value>
            <description>The amount of off heap memory (in megabytes) to be allocated for the executor</description>
        </property>        
        <property>
            <name>citationmatchingFuzzySparkExecutorCores</name>
            <value>${sparkExecutorCores}</value>
            <description>number of cores used by single executor</description>
        </property>
        <property>
            <name>citationmatchingFuzzyNumberOfPartitions</name>
            <description>number of partitions used for rdds with citations and documents read from input files</description>
        </property>
        <property>
            <name>citationmatchingFuzzyCacheLocation</name>
            <description>fuzzy citation matching HDFS cache location</description>
        </property>
        <property>
            <name>referenceextractionCommunitySparkDriverMemory</name>
            <value>${sparkDriverMemory}</value>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>referenceextractionCommunitySparkExecutorMemory</name>
            <value>${sparkExecutorMemory}</value>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>referenceextractionCommunitySparkExecutorCores</name>
            <value>${sparkExecutorCores}</value>
            <description>number of cores used by single executor</description>
        </property>
        <property>
            <name>referenceextractionSoftwareSparkDriverMemory</name>
            <value>${sparkDriverMemory}</value>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>referenceextractionSoftwareSparkExecutorMemory</name>
            <value>${sparkExecutorMemory}</value>
            <description>memory for individual executor</description>
        </property>
        <property>
            <name>textUnionBlockSize</name>
            <value>128m</value>
            <description>DocumentText datastore block size affecting number of tasks issued by each text mining module.
            Introduced to prevent long lasting tasks from occupying cluster resources for too long.</description>
        </property>
        <!-- patents remote EPO endpoint related -->
        <property>
            <name>patentServiceAuthnConsumerKey</name>
            <description>remote EPO endpoint API authentication consumer key, required by OpenPatentWebServiceFacadeFactory</description>
        </property>
        <property>
            <name>patentServiceAuthnConsumerSecret</name>
            <description>remote EPO endpoint API authentication consumer secret, required by OpenPatentWebServiceFacadeFactory</description>
        </property>
        <property>
            <name>patentServiceEndpointAuthHost</name>
            <description>remote EPO endpoint authentication host, required by OpenPatentWebServiceFacadeFactory</description>
        </property>
        <property>
            <name>patentServiceEndpointAuthUriRoot</name>
            <description>remote EPO endpoint authentication URI root, required by OpenPatentWebServiceFacadeFactory</description>
        </property>
        <property>
            <name>patentServiceEndpointOpsHost</name>
            <description>remote EPO endpoint OPS host, required by OpenPatentWebServiceFacadeFactory</description>
        </property>
        <property>
            <name>patentServiceEndpointOpsUriRoot</name>
            <description>remote EPO endpoint OPS URI root, required by OpenPatentWebServiceFacadeFactory</description>
        </property>
        <property>
            <name>patent_cache_location</name>
            <description>patent HDFS cache location</description>
        </property>
        <!-- output ports -->
        <property>
            <name>output_merged_metadata</name>
            <description>metadata merging output directory containing eu.dnetlib.iis.transformers.metadatamerger.schemas.ExtractedDocumentMetadataMergedWithOriginal avro records.</description>
        </property>
        <property>
            <name>output_document_to_project</name>
            <description>project reference extraction output directory</description>
        </property>
        <property>
            <name>output_document_to_dataset</name>
            <description>dataset reference extraction output directory</description>
        </property>
        <property>
            <name>output_document_to_research_initiatives</name>
            <description>research initiatives reference extraction output directory</description>
        </property>
         <property>
            <name>output_document_to_community</name>
            <description>community reference extraction output directory</description>
        </property>
        <property>
            <name>output_document_to_pdb</name>
            <description>protein databank reference extraction output directory</description>
        </property>
        <property>
            <name>output_document_to_covid19</name>
            <description>covid19 reference extraction output directory</description>
        </property>
        <property>
            <name>output_document_to_service</name>
            <description>EOSC service reference extraction output directory</description>
        </property>
        <property>
            <name>output_document_to_software_url</name>
            <description>software url reference extraction output directory</description>
        </property>
        <property>
            <name>output_document_to_document_classes</name>
            <description>output document classification directory</description>
        </property>
        <property>
            <name>output_citation</name>
            <description>output containing grouped citations coming from citation fuzzy and direct matching modules</description>
        </property>
        <property>
            <name>output_document_similarity</name>
            <description>output document similarity directory</description>
        </property>
        <property>
            <name>output_matched_doc_organizations</name>
            <description>output matched document organizations directory</description>
        </property>
        <property>
            <name>output_document_to_patent</name>
            <description>patent reference extraction output directory</description>
        </property>
        <property>
            <name>output_patent_metadata</name>
            <description>patent metadata retrived from EPO endpoint output directory</description>
        </property>
        
        <property>
            <name>output_report_root_path</name>
            <description>base directory for storing reports</description>
        </property>
        <property>
            <name>metric_pusher_address</name>
            <description>pushgateway service location</description>
        </property>
    </parameters>

    <global>
        <job-tracker>${jobTracker}</job-tracker>
        <name-node>${nameNode}</name-node>
        <configuration>
            <property>
                <name>mapreduce.job.queuename</name>
                <value>${queueName}</value>
            </property>
            <property>
                <name>oozie.launcher.mapred.job.queue.name</name>
                <value>${oozieLauncherQueueName}</value>
            </property>
        </configuration>
    </global>

    <start to="transformers_extracted_document_metadata_to_text" />

    <action name="transformers_extracted_document_metadata_to_text">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformer_metadataextraction_documenttext</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformer_metadataextraction_documenttext/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${input_extracted_document_metadata}</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/transformer_metadataextraction_documenttext/out</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="transformers_common_union_document_text" />
        <error to="fail" />
    </action>

    <action name="transformers_common_union_document_text">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_common_union</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_common_union_document_text/working_dir</value>
                </property>
                <property>
                    <name>input_a</name>
                    <value>${workingDir}/transformer_metadataextraction_documenttext/out</value>
                </property>
                <property>
                    <name>input_b</name>
                    <value>${input_document_text}</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/transformers_common_union_document_text/out</value>
                </property>
                <property>
                    <name>schema</name>
                    <value>eu.dnetlib.iis.metadataextraction.schemas.DocumentText</value>
                </property>
                <property>
                    <name>output_report</name>
                    <value>${output_report_root_path}/document_text_union</value>
                </property>
                <property>
                    <name>union_count_report_key</name>
                    <value>processing.merging.documentText</value>
                </property>
                <property>
                    <name>dfs_blocksize</name>
                    <value>${textUnionBlockSize}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="extracted_document_metadata_collapser" />
        <error to="fail" />
    </action>


    <!-- collapsed extracted metadata records branch -->

    <action name="extracted_document_metadata_collapser">
        <sub-workflow>
            <app-path>${wf:appPath()}/collapsers_basic_collapser</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/extracted_document_metadata_collapser/working_dir</value>
                </property>
                <property>
                    <name>blocking_field</name>
                    <value>id</value>
                </property>
                <property>
                    <name>significant_fields</name>
                    <value>references,publicationTypeName,abstract,externalIdentifiers,title,journal,pages,year</value>
                </property>
                <property>
                    <name>schema</name>
                    <value>eu.dnetlib.iis.metadataextraction.schemas.ExtractedDocumentMetadata</value>
                </property>
                <!-- Input ports. -->
                <property>
                    <name>input</name>
                    <value>${input_extracted_document_metadata}</value>
                </property>
                <!-- Output port bound to given path -->
                <property>
                    <name>output</name>
                    <value>${workingDir}/extracted_document_metadata_collapser/output</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="transformers_metadatamerger" />
        <error to="fail" />
    </action>

    <action name="transformers_metadatamerger">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_metadatamerger</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_metadatamerger/working_dir</value>
                </property>
                <property>
                    <name>input_base_metadata</name>
                    <value>${input_document_metadata}</value>
                </property>
                <property>
                    <name>input_extracted_metadata</name>
                    <value>${workingDir}/extracted_document_metadata_collapser/output</value>
                </property>
                <property>
                    <name>output_merged_metadata</name>
                    <value>${output_merged_metadata}</value>
                </property>
            </configuration>
        </sub-workflow>

        <ok to="forking" />
        <error to="fail" />
    </action>

    <fork name="forking">
        <path start="decision-referenceextraction_project" />
        <path start="decision-referenceextraction_dataset" />
        <path start="decision-referenceextraction_pdb" />
        <path start="decision-referenceextraction_software_url" />
        <path start="decision-referenceextraction_patent" />
        <path start="decision-referenceextraction_covid19" />
        <path start="decision-referenceextraction_service" />
    </fork>

    <!-- start of project reference extraction block -->
    <decision name="decision-referenceextraction_project">
        <switch>
            <case to="ingest_webcrawl_fundings">${active_referenceextraction_project eq "true"}</case>
            <default to="skip-referenceextraction_project" />
        </switch>
    </decision>

    <action name="ingest_webcrawl_fundings">
        <sub-workflow>
            <app-path>${wf:appPath()}/ingest_webcrawl_fundings</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/ingest_webcrawl_fundings/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${input_document_text_wos}</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/ingest_webcrawl_fundings/output</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="union_project_referenceextraction_text_input" />
        <error to="fail" />
    </action>

    <action name="union_project_referenceextraction_text_input">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_common_union</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_union_project_referenceextraction_text_input/working_dir</value>
                </property>
                <property>
                    <name>input_a</name>
                    <value>${workingDir}/transformers_common_union_document_text/out</value>
                </property>
                <property>
                    <name>input_b</name>
                    <value>${workingDir}/ingest_webcrawl_fundings/output</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/transformers_union_project_referenceextraction_text_input/output</value>
                </property>
                <property>
                    <name>schema</name>
                    <value>eu.dnetlib.iis.metadataextraction.schemas.DocumentText</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="transformers_project_filter" />
        <error to="fail" />
    </action>

    <action name="transformers_project_filter">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_project_filter</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_project_filter/working_dir</value>
                </property>
                <property>
                    <name>fundingclass_blacklist_regex</name>
                    <value>${referenceextraction_project_fundingclass_blacklist_regex}</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${input_project}</value>
                </property>
                <property>
                    <name>output_approved</name>
                    <value>${workingDir}/transformers_project_filter/output_approved</value>
                </property>
                <property>
                    <name>output_rejected</name>
                    <value>${workingDir}/transformers_project_filter/output_rejected</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="referenceextraction_project" />
        <error to="fail" />
    </action>

    <action name="referenceextraction_project">
        <sub-workflow>
            <app-path>${wf:appPath()}/referenceextraction_project</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/referenceextraction_project/working_dir</value>
                </property>
                <property>
                    <name>input_document_text</name>
                    <value>${workingDir}/transformers_union_project_referenceextraction_text_input/output</value>
                </property>
                <property>
                    <name>input_project</name>
                    <value>${workingDir}/transformers_project_filter/output_approved</value>
                </property>
                <property>
                    <name>input_document_metadata</name>
                    <value>${output_merged_metadata}</value>
                </property>
                <property>
                    <name>output_document_to_project</name>
                    <!-- referenceextraction_project directory is created at subworkflow prepare phase -->
                    <value>${output_document_to_project}</value>
                </property>
                <property>
                    <name>sparkDriverMemory</name>
                    <value>${projectReferenceExtractionSparkDriverMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorMemory</name>
                    <value>${projectReferenceExtractionSparkExecutorMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorCores</name>
                    <value>${projectReferenceExtractionSparkExecutorCores}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="joining" />
        <error to="fail" />
    </action>

    <action name="skip-referenceextraction_project">
        <java>
            <prepare>
                <!-- notice: directory have to aligned with skipped action output -->
                <delete path="${nameNode}${workingDir}/referenceextraction_project" />
                <delete path="${nameNode}${output_document_to_project}" />
                <mkdir path="${nameNode}${workingDir}/referenceextraction_project" />
                <mkdir path="${nameNode}${output_document_to_project}" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{referenceextraction_project,
                eu.dnetlib.iis.referenceextraction.project.schemas.DocumentToProject,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <!-- notice: directory have to aligned with skipped action output -->
            <arg>-Oreferenceextraction_project=${output_document_to_project}</arg>
        </java>
        <ok to="joining" />
        <error to="fail" />
    </action>
    <!-- end of project reference extraction block -->

    <!-- start of dataset reference extraction block -->
    <decision name="decision-referenceextraction_dataset">
        <switch>
            <case to="referenceextraction_dataset">${active_referenceextraction_dataset eq "true"}</case>
            <default to="skip-referenceextraction_dataset" />
        </switch>
    </decision>

    <action name="referenceextraction_dataset">
        <sub-workflow>
            <app-path>${wf:appPath()}/referenceextraction_dataset</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/referenceextraction_dataset/working_dir</value>
                </property>
                <property>
                    <name>input_document_text</name>
                    <value>${workingDir}/transformers_common_union_document_text/out</value>
                </property>
                <property>
                    <name>input_dataset</name>
                    <value>${input_dataset}</value>
                </property>
                <property>
                    <name>output_document_to_dataset</name>
                    <!-- referenceextraction_dataset directory is created at subworkflow prepare phase -->
                    <value>${output_document_to_dataset}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="joining" />
        <error to="fail" />
    </action>

    <action name="skip-referenceextraction_dataset">
        <java>
            <prepare>
                <!-- notice: directory have to aligned with skipped action output -->
                <delete path="${nameNode}${workingDir}/referenceextraction_dataset" />
                <delete path="${nameNode}${output_document_to_dataset}" />
                <mkdir path="${nameNode}${workingDir}/referenceextraction_dataset" />
                <mkdir path="${nameNode}${output_document_to_dataset}" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{referenceextraction_dataset,
                eu.dnetlib.iis.referenceextraction.dataset.schemas.DocumentToDataSet,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <!-- notice: directory have to aligned with skipped action output -->
            <arg>-Oreferenceextraction_dataset=${output_document_to_dataset}</arg>
        </java>
        <ok to="joining" />
        <error to="fail" />
    </action>
    <!-- end of dataset reference extraction block -->

    <!-- start of pdb reference extraction block -->
    <decision name="decision-referenceextraction_pdb">
        <switch>
            <case to="referenceextraction_pdb">${active_referenceextraction_pdb eq "true"}</case>
            <default to="skip-referenceextraction_pdb" />
        </switch>
    </decision>

    <action name="referenceextraction_pdb">
        <sub-workflow>
            <app-path>${wf:appPath()}/referenceextraction_pdb</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/referenceextraction_pdb/working_dir</value>
                </property>
                <property>
                    <name>input_document_text</name>
                    <value>${workingDir}/transformers_common_union_document_text/out</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/referenceextraction_pdb/output</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="transformers_export_pdb" />
        <error to="fail" />
    </action>

    <action name="transformers_export_pdb">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_export_concepts</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_export_pdb/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/referenceextraction_pdb/output</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${output_document_to_pdb}</value>
                </property>
                <property>
                    <name>output_report_relative_path</name>
                    <value>doc_pdb</value>
                </property>
                <property>
                    <name>output_report_record_read_counter_name</name>
                    <value>processing.referenceExtraction.pdb.references</value>
                </property>
                <property>
                    <name>output_report_record_written_counter_name</name>
                    <value>processing.referenceExtraction.pdb.docs</value>
                </property>
            </configuration>
        </sub-workflow>

        <ok to="joining" />
        <error to="fail" />
    </action>

    <action name="skip-referenceextraction_pdb">
        <java>
            <prepare>
                <!-- notice: directory have to aligned with skipped action output -->
                <delete path="${nameNode}${workingDir}/transformers_export_pdb" />
                <delete path="${nameNode}${output_document_to_pdb}" />
                <mkdir path="${nameNode}${workingDir}/transformers_export_pdb" />
                <mkdir path="${nameNode}${output_document_to_pdb}" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{referenceextraction_pdb,
                eu.dnetlib.iis.export.schemas.DocumentToConceptIds,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <!-- notice: directory have to aligned with skipped action output -->
            <arg>-Oreferenceextraction_pdb=${output_document_to_pdb}</arg>
        </java>
        <ok to="joining" />
        <error to="fail" />
    </action>
    <!-- end of pdb reference extraction block -->

    <!-- start of software url reference extraction block -->
    <decision name="decision-referenceextraction_software_url">
        <switch>
            <case to="referenceextraction_software_url">${active_referenceextraction_software_url eq "true"}</case>
            <default to="skip-referenceextraction_software_url" />
        </switch>
    </decision>

    <action name="referenceextraction_software_url">
        <sub-workflow>
            <app-path>${wf:appPath()}/referenceextraction_software_url</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/referenceextraction_software_url/working_dir</value>
                </property>
                <property>
                    <name>input_document_text</name>
                    <value>${workingDir}/transformers_common_union_document_text/out</value>
                </property>
                <property>
                    <name>cacheRootDir</name>
                    <value>${software_webcrawl_cache_location}</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${output_document_to_software_url}</value>
                </property>
                <property>
                    <name>sparkDriverMemory</name>
                    <value>${referenceextractionSoftwareSparkDriverMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorMemory</name>
                    <value>${referenceextractionSoftwareSparkExecutorMemory}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="joining" />
        <error to="fail" />
    </action>

    <action name="skip-referenceextraction_software_url">
        <java>
            <prepare>
                <!-- notice: directory have to aligned with skipped action output -->
                <delete path="${nameNode}${output_document_to_software_url}" />
                <mkdir path="${nameNode}${output_document_to_software_url}" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{referenceextraction_software_url,
                eu.dnetlib.iis.referenceextraction.softwareurl.schemas.DocumentToSoftwareUrlWithMeta,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <!-- notice: directory have to aligned with skipped action output -->
            <arg>-Oreferenceextraction_software_url=${output_document_to_software_url}</arg>
        </java>
        <ok to="joining" />
        <error to="fail" />
    </action>
    <!-- end of software url extraction block -->

    <!-- start of patent reference extraction block -->
    <decision name="decision-referenceextraction_patent">
        <switch>
            <case to="referenceextraction_patent">${active_referenceextraction_patent eq "true"}</case>
            <default to="skip-referenceextraction_patent" />
        </switch>
    </decision>

    <action name="referenceextraction_patent">
        <sub-workflow>
            <app-path>${wf:appPath()}/referenceextraction_patent</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/referenceextraction_patent/working_dir</value>
                </property>
                <property>
                    <name>input_document_text</name>
                    <value>${workingDir}/transformers_common_union_document_text/out</value>
                </property>
                <property>
                    <name>cacheRootDir</name>
                    <value>${patent_cache_location}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="joining" />
        <error to="fail" />
    </action>

    <action name="skip-referenceextraction_patent">
        <java>
            <prepare>
                <delete path="${nameNode}${output_document_to_patent}" />
                <delete path="${nameNode}${output_patent_metadata}" />
                <mkdir path="${nameNode}${output_document_to_patent}" />
                <mkdir path="${nameNode}${output_patent_metadata}" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{referenceextraction_patent,
                eu.dnetlib.iis.referenceextraction.patent.schemas.DocumentToPatent,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <arg>-C{patent_metadata,
                eu.dnetlib.iis.referenceextraction.patent.schemas.Patent,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <arg>-Oreferenceextraction_patent=${output_document_to_patent}</arg>
            <arg>-Opatent_metadata=${output_patent_metadata}</arg>
        </java>
        <ok to="joining" />
        <error to="fail" />
    </action>
    <!-- end of patent extraction block -->

    <join name="joining" to="decision-referenceextraction_researchinitiative" />

    <!-- start of researchinitiative reference extraction block -->
    <decision name="decision-referenceextraction_researchinitiative">
        <switch>
            <case to="referenceextraction_researchinitiative">${active_referenceextraction_researchinitiative eq "true"}</case>
            <default to="skip-referenceextraction_researchinitiative" />
        </switch>
    </decision>

    <action name="referenceextraction_researchinitiative">
        <sub-workflow>
            <app-path>${wf:appPath()}/referenceextraction_researchinitiative</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/referenceextraction_researchinitiative/working_dir</value>
                </property>
                <property>
					<name>input_document_metadata</name>
					<value>${output_merged_metadata}</value>
				</property>
                <property>
                    <name>input_document_text</name>
                    <value>${workingDir}/transformers_common_union_document_text/out</value>
                </property>
                <property>
                    <name>input_concept</name>
                    <value>${input_concept}</value>
                </property>
                <property>
                    <name>sparkDriverMemory</name>
                    <value>${researchInitiativeReferenceExtractionSparkDriverMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorMemory</name>
                    <value>${researchInitiativeReferenceExtractionSparkExecutorMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorCores</name>
                    <value>${researchInitiativeReferenceExtractionSparkExecutorCores}</value>
                </property>
                <property>
                    <name>sparkExecutorOverhead</name>
                    <value>${researchInitiativeReferenceExtractionSparkExecutorOverhead}</value>
                </property>
                <property>
                    <name>output_document_to_research_initiative</name>
                    <value>${workingDir}/referenceextraction_researchinitiative/output</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="transformers_export_researchinitiatives" />
        <error to="fail" />
    </action>

    <action name="transformers_export_researchinitiatives">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_export_concepts</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_export_researchinitiatives/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/referenceextraction_researchinitiative/output</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${output_document_to_research_initiatives}</value>
                </property>
                <property>
                    <name>output_report_relative_path</name>
                    <value>doc_research_initiative</value>
                </property>
                <property>
                    <name>output_report_record_read_counter_name</name>
                    <value>processing.referenceExtraction.researchInitiative.references</value>
                </property>
                <property>
                    <name>output_report_record_written_counter_name</name>
                    <value>processing.referenceExtraction.researchInitiative.docs</value>
                </property>
            </configuration>
        </sub-workflow>

        <ok to="decision-referenceextraction_community" />
        <error to="fail" />
    </action>

    <action name="skip-referenceextraction_researchinitiative">
        <java>
            <prepare>
                <!-- notice: directory have to aligned with skipped action output -->
                <delete path="${nameNode}${workingDir}/transformers_export_researchinitiatives" />
                <delete path="${nameNode}${output_document_to_research_initiatives}" />
                <mkdir path="${nameNode}${workingDir}/transformers_export_researchinitiatives" />
                <mkdir path="${nameNode}${output_document_to_research_initiatives}" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{referenceextraction_researchinitiatives,
                eu.dnetlib.iis.export.schemas.DocumentToConceptIds,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <!-- notice: directory have to aligned with skipped action output -->
            <arg>-Oreferenceextraction_researchinitiatives=${output_document_to_research_initiatives}</arg>
        </java>
        <ok to="decision-referenceextraction_community" />
        <error to="fail" />
    </action>
    <!-- end of researchinitiative reference extraction block -->

	<!-- start of community reference extraction block -->
    <decision name="decision-referenceextraction_community">
        <switch>
            <case to="referenceextraction_community">${active_referenceextraction_community eq "true"}</case>
            <default to="skip-referenceextraction_community" />
        </switch>
    </decision>

    <action name="referenceextraction_community">
        <sub-workflow>
            <app-path>${wf:appPath()}/referenceextraction_community</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/referenceextraction_community/working_dir</value>
                </property>
                <property>
                    <name>input_concept</name>
                    <value>${input_concept}</value>
                </property>
                <property>
                    <name>input_document_text</name>
                    <value>${workingDir}/transformers_common_union_document_text/out</value>
                </property>
                <property>
                    <name>output_document_to_concept</name>
                    <value>${workingDir}/referenceextraction_community/output</value>
                </property>
                
                <property>
                    <name>sparkDriverMemory</name>
                    <value>${referenceextractionCommunitySparkDriverMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorMemory</name>
                    <value>${referenceextractionCommunitySparkExecutorMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorCores</name>
                    <value>${referenceextractionCommunitySparkExecutorCores}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="transformers_export_communities" />
        <error to="fail" />
    </action>

    <action name="transformers_export_communities">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_export_concepts</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_export_communities/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/referenceextraction_community/output</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${output_document_to_community}</value>
                </property>
                <property>
                    <name>output_report_relative_path</name>
                    <value>doc_community</value>
                </property>
                <property>
                    <name>output_report_record_read_counter_name</name>
                    <value>processing.referenceExtraction.community.references.total</value>
                </property>
                <property>
                    <name>output_report_record_written_counter_name</name>
                    <value>processing.referenceExtraction.community.docs</value>
                </property>
            </configuration>
        </sub-workflow>

        <ok to="decision-documentsclassification" />
        <error to="fail" />
    </action>

    <action name="skip-referenceextraction_community">
        <java>
            <prepare>
                <!-- notice: directory have to aligned with skipped action output -->
                <delete path="${nameNode}${workingDir}/transformers_export_communities" />
                <delete path="${nameNode}${output_document_to_community}" />
                <mkdir path="${nameNode}${workingDir}/transformers_export_communities" />
                <mkdir path="${nameNode}${output_document_to_community}" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{referenceextraction_communities,
                eu.dnetlib.iis.export.schemas.DocumentToConceptIds,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <!-- notice: directory have to aligned with skipped action output -->
            <arg>-Oreferenceextraction_communities=${output_document_to_community}</arg>
        </java>
        <ok to="decision-documentsclassification" />
        <error to="fail" />
    </action>
    <!-- end of researchinitiative reference extraction block -->


    <!-- start of covid19 reference extraction block -->
    <decision name="decision-referenceextraction_covid19">
        <switch>
            <case to="referenceextraction_covid19">${active_referenceextraction_covid19 eq "true"}</case>
            <default to="skip-referenceextraction_covid19" />
        </switch>
    </decision>

    <action name="referenceextraction_covid19">
        <sub-workflow>
            <app-path>${wf:appPath()}/referenceextraction_covid19</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/referenceextraction_covid19/working_dir</value>
                </property>
                <property>
                    <name>input_document_metadata</name>
                    <value>${output_merged_metadata}</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/referenceextraction_covid19/output</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="transformers_export_covid19" />
        <error to="fail" />
    </action>

    <action name="transformers_export_covid19">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_export_concepts</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_export_covid19/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/referenceextraction_covid19/output</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${output_document_to_covid19}</value>
                </property>
                <property>
                    <name>output_report_relative_path</name>
                    <value>doc_covid19</value>
                </property>
                <property>
                    <name>output_report_record_read_counter_name</name>
                    <value>processing.referenceExtraction.covid-19.references</value>
                </property>
                <property>
                    <name>output_report_record_written_counter_name</name>
                    <value>processing.referenceExtraction.covid-19.docs</value>
                </property>
            </configuration>
        </sub-workflow>

        <ok to="joining" />
        <error to="fail" />
    </action>

    <action name="skip-referenceextraction_covid19">
        <java>
            <prepare>
                <!-- notice: directory have to aligned with skipped action output -->
                <delete path="${nameNode}${workingDir}/transformers_export_covid19" />
                <delete path="${nameNode}${output_document_to_covid19}" />
                <mkdir path="${nameNode}${workingDir}/transformers_export_covid19" />
                <mkdir path="${nameNode}${output_document_to_covid19}" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{referenceextraction_covid19,
                eu.dnetlib.iis.export.schemas.DocumentToConceptIds,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <!-- notice: directory have to aligned with skipped action output -->
            <arg>-Oreferenceextraction_covid19=${output_document_to_covid19}</arg>
        </java>
        <ok to="joining" />
        <error to="fail" />
    </action>
    <!-- end of covid19 reference extraction block -->

	<!-- start of EOSC service reference extraction block -->
    <decision name="decision-referenceextraction_service">
        <switch>
            <case to="referenceextraction_service">${active_referenceextraction_eoscservice eq "true"}</case>
            <default to="skip-referenceextraction_service" />
        </switch>
    </decision>

    <action name="referenceextraction_service">
        <sub-workflow>
            <app-path>${wf:appPath()}/referenceextraction_service</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/referenceextraction_service/working_dir</value>
                </property>
                <property>
                    <name>input_document_text</name>
                    <value>${workingDir}/transformers_common_union_document_text/out</value>
                </property>
                <property>
                    <name>input_service</name>
                    <value>${input_service}</value>
                </property>
                <property>
                    <name>output_document_to_service</name>
                    <value>${output_document_to_service}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="joining" />
        <error to="fail" />
    </action>

    <action name="skip-referenceextraction_service">
        <java>
            <prepare>
                <delete path="${nameNode}${output_document_to_service}" />
                <mkdir path="${nameNode}${output_document_to_service}" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{referenceextraction_service,
                eu.dnetlib.iis.referenceextraction.service.schemas.DocumentToService,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <arg>-Oreferenceextraction_service=${output_document_to_service}</arg>
        </java>
        <ok to="joining" />
        <error to="fail" />
    </action>
    <!-- end of EOSC service reference extraction block -->


    <!-- start of documents classification part -->
    <decision name="decision-documentsclassification">
        <switch>
            <case to="documentsclassification">${active_documentsclassification eq "true"}</case>
            <default to="skip-documentsclassification" />
        </switch>
    </decision>


    <action name="documentsclassification">
        <sub-workflow>
            <app-path>${wf:appPath()}/documentsclassification</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/documentsclassification/working_dir</value>
                </property>
                <property>
                    <name>input_documents</name>
                    <value>${output_merged_metadata}</value>
                </property>
                <property>
                    <name>output_document_to_document_classes</name>
                    <value>${output_document_to_document_classes}</value>
                </property>
                <property>
                    <name>sparkDriverMemory</name>
                    <value>${documentsclassificationSparkDriverMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorMemory</name>
                    <value>${documentsclassificationSparkExecutorMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorCores</name>
                    <value>${documentsclassificationSparkExecutorCores}</value>
                </property>
                <property>
                    <name>numberOfPartitions</name>
                    <value>${documentsclassificationNumberOfPartitions}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="decision-citationmatching" />
        <error to="fail" />
    </action>

    <action name="skip-documentsclassification">
        <java>
            <prepare>
                <!-- notice: directory have to aligned with skipped action output -->
                <delete path="${nameNode}${workingDir}/documentsclassification" />
                <delete path="${nameNode}${output_document_to_document_classes}" />
                <mkdir path="${nameNode}${workingDir}/documentsclassification" />
                <mkdir path="${nameNode}${output_document_to_document_classes}" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{documentsclassification,
                eu.dnetlib.iis.documentsclassification.schemas.DocumentToDocumentClasses,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <!-- notice: directory have to aligned with skipped action output -->
            <arg>-Odocumentsclassification=${output_document_to_document_classes}</arg>
        </java>
        <ok to="decision-citationmatching" />
        <error to="fail" />
    </action>
    <!-- end of documents classification part -->

    <!-- citation matching part -->
    <decision name="decision-citationmatching">
        <switch>
            <case to="citationmatching_direct">${active_citationmatching eq "true"}</case>
            <default to="skip-citationmatching" />
        </switch>
    </decision>

    <action name="citationmatching_direct">
        <sub-workflow>
            <app-path>${wf:appPath()}/citationmatching_direct</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/citationmatching_direct/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${output_merged_metadata}</value>
                </property>
                <property>
                    <name>inputPmcIdsMappingCSV</name>
                    <value>${citationmatchingDirectPmcIdsMappingCSV}</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/citationmatching_direct/output</value>
                </property>
                <property>
                    <name>sparkExecutorMemory</name>
                    <value>${citationmatchingDirectSparkExecutorMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorOverhead</name>
                    <value>${citationmatchingDirectSparkExecutorOverhead}</value>
                </property>
                <property>
                    <name>sparkExecutorCores</name>
                    <value>${citationmatchingDirectSparkExecutorCores}</value>
                </property>
                <property>
                    <name>sparkDriverMemory</name>
                    <value>${citationmatchingDirectSparkDriverMemory}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="citationmatching_fuzzy" />
        <error to="fail" />
    </action>

    <action name="citationmatching_fuzzy">
        <sub-workflow>
            <app-path>${wf:appPath()}/citationmatching_fuzzy</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/citationmatching_fuzzy/working_dir</value>
                </property>
                <property>
                    <name>input_metadata</name>
                    <value>${output_merged_metadata}</value>
                </property>
                <property>
                    <name>input_matched_citations</name>
                    <value>${workingDir}/citationmatching_direct/output</value>
                </property>
                <property>
                    <name>output_citations</name>
                    <value>${workingDir}/citationmatching_fuzzy/output</value>
                </property>
                <property>
                    <name>sparkDriverMemory</name>
                    <value>${citationmatchingFuzzySparkDriverMemory}</value>
                </property>
                <property>
                    <name>sparkDriverOverhead</name>
                    <value>${citationmatchingFuzzySparkDriverOverhead}</value>
                </property>
                <property>
                    <name>sparkExecutorMemory</name>
                    <value>${citationmatchingFuzzySparkExecutorMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorOverhead</name>
                    <value>${citationmatchingFuzzySparkExecutorOverhead}</value>
                </property>
                <property>
                    <name>sparkExecutorCores</name>
                    <value>${citationmatchingFuzzySparkExecutorCores}</value>
                </property>
                <property>
                    <name>numberOfPartitions</name>
                    <value>${citationmatchingFuzzyNumberOfPartitions}</value>
                </property>
                <property>
                    <name>cacheRootDir</name>
                    <value>${citationmatchingFuzzyCacheLocation}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="transformers_citations_from_referencemetadata" />
        <error to="fail" />
    </action>

    <action name="transformers_citations_from_referencemetadata">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_citations_from_referencemetadata</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_citations_from_referencemetadata/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${output_merged_metadata}</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/transformers_citations_from_referencemetadata/output</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="citations_union" />
        <error to="fail" />
    </action>

    <action name="citations_union">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_common_union3</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/citations_union/working_dir</value>
                </property>
                <property>
                    <name>input_a</name>
                    <value>${workingDir}/citationmatching_direct/output</value>
                </property>
                <property>
                    <name>input_b</name>
                    <value>${workingDir}/citationmatching_fuzzy/output</value>
                </property>
                <property>
                    <name>input_c</name>
                    <value>${workingDir}/transformers_citations_from_referencemetadata/output</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/citations_union/output</value>
                </property>
                <property>
                    <name>schema</name>
                    <value>eu.dnetlib.iis.common.citations.schemas.Citation</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="citations_collapser" />
        <error to="fail" />
    </action>

    <action name="citations_collapser">
        <sub-workflow>
            <app-path>${wf:appPath()}/collapsers_citation_collapser</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/citations_collapser/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/citations_union/output</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/citations_collapser/output</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="transformers_export_citations" />
        <error to="fail" />
    </action>

    <!-- grouping citations for the same publication -->
    <action name="transformers_export_citations">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_export_citations</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_export_citations/working_dir</value>
                </property>
                <property>
                    <name>input</name>
                    <value>${workingDir}/citations_collapser/output</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${output_citation}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="decision-documentssimilarity" />
        <error to="fail" />
    </action>

    <!-- end of normalize and group citations part -->
    <action name="skip-citationmatching">
        <java>
            <prepare>
                <!-- notice: directory have to aligned with skipped action output -->
                <delete path="${nameNode}${workingDir}/transformers_export_citations" />
                <mkdir path="${nameNode}${workingDir}/transformers_export_citations" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{citations,
                eu.dnetlib.iis.export.schemas.Citations,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <!-- notice: directory have to aligned with skipped action output -->
            <arg>-Ocitations=${output_citation}</arg>
        </java>
        <ok to="decision-documentssimilarity" />
        <error to="fail" />
    </action>
    <!-- end of citation matching part -->

    <!-- start of documents similarity part -->
    <!-- running documentsimilarity sequentially to all the other KDM modules due to the lack of memory when executed in parallel -->
    <decision name="decision-documentssimilarity">
        <switch>
            <case to="transformers_documentssimilarity">${active_documentssimilarity eq "true"}</case>
            <default to="skip-documentssimilarity" />
        </switch>
    </decision>

    <action name="transformers_documentssimilarity">
        <sub-workflow>
            <app-path>${wf:appPath()}/transformers_documentssimilarity</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/transformers_documentssimilarity/working_dir</value>
                </property>
                <property>
                    <name>input_metadata</name>
                    <value>${output_merged_metadata}</value>
                </property>
                <property>
                    <name>output_document_metadata</name>
                    <value>${workingDir}/transformers_documentssimilarity/output_document_metadata</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="documentssimilarity_chain" />
        <error to="fail" />
    </action>

    <action name="documentssimilarity_chain">
        <sub-workflow>
            <app-path>${wf:appPath()}/documentssimilarity_chain</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>workingDir</name>
                    <value>${workingDir}/documentssimilarity_chain/working_dir</value>
                </property>
                <property>
                    <name>input_document</name>
                    <value>${workingDir}/transformers_documentssimilarity/output_document_metadata</value>
                </property>
                <property>
                    <name>output_documents_similarity</name>
                    <value>${output_document_similarity}</value>
                </property>
                <property>
                    <name>parallel</name>
                    <value>${ds_parallel}</value>
                </property>
                <property>
                    <name>mapredChildJavaOpts</name>
                    <value>${ds_mapredChildJavaOpts}</value>
                </property>
                <property>
                    <name>sample</name>
                    <value>${ds_sample}</value>
                </property>
                <property>
                    <name>removal_rate</name>
                    <value>${ds_removal_rate}</value>
                </property>
                <property>
                    <name>removal_least_used</name>
                    <value>${ds_removal_least_used}</value>
                </property>
                <property>
                    <name>tfidfTopnTermPerDocument</name>
                    <value>${ds_tfidfTopnTermPerDocument}</value>
                </property>
                <property>
                    <name>similarityTopnDocumentPerDocument</name>
                    <value>${ds_similarityTopnDocumentPerDocument}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="decision-affiliation-matching" />
        <error to="fail" />
    </action>

    <action name="skip-documentssimilarity">
        <java>
            <prepare>
                <!-- notice: directory have to aligned with skipped action output -->
                <delete path="${nameNode}${workingDir}/documentssimilarity_chain" />
                <delete path="${nameNode}${output_document_similarity}" />
                <mkdir path="${nameNode}${workingDir}/documentssimilarity_chain" />
                <mkdir path="${nameNode}${output_document_similarity}" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{documentssimilarity,
                eu.dnetlib.iis.documentssimilarity.schemas.DocumentSimilarity,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <!-- notice: directory have to aligned with skipped action output -->
            <arg>-Odocumentssimilarity=${output_document_similarity}</arg>
        </java>
        <ok to="decision-affiliation-matching" />
        <error to="fail" />
    </action>
    <!-- end of documents similarity part -->


    <!-- start of affiliation matching part -->
    <decision name="decision-affiliation-matching" >
        <switch>
            <case to="affiliation-matching">${active_document_affiliation eq "true"}</case>
            <default to="skip-affiliation-matching" />
        </switch>
    </decision>

    <action name="affiliation-matching">
        <sub-workflow>
            <app-path>${wf:appPath()}/affiliation_matching</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>input_document_metadata</name>
                    <value>${input_extracted_document_metadata}</value>
                </property>
                <property>
                    <name>input_organizations</name>
                    <value>${input_organizations}</value>
                </property>
                <property>
                    <name>input_document_to_project</name>
                    <value>${input_document_to_project}</value>
                </property>
                <property>
                    <name>input_inferred_document_to_project</name>
                    <value>${output_document_to_project}</value>
                </property>
                <property>
                    <name>input_project_to_organization</name>
                    <value>${input_project_to_organization}</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/affiliation_matching/output</value>
                </property>
                <property>
                    <name>sparkExecutorMemory</name>
                    <value>${affiliationmatchingSparkExecutorMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorCores</name>
                    <value>${affiliationmatchingSparkExecutorCores}</value>
                </property>
                <property>
                    <name>sparkDriverMemory</name>
                    <value>${affiliationmatchingSparkDriverMemory}</value>
                </property>
                <property>
                    <name>sparkDriverOverhead</name>
                    <value>${affiliationmatchingSparkDriverOverhead}</value>
                </property>
                
            </configuration>
        </sub-workflow>
        <ok to="affiliation-matching-project-based" />
        <error to="fail" />
    </action>

    <action name="affiliation-matching-project-based">
        <sub-workflow>
            <app-path>${wf:appPath()}/affiliation_matching_project_based</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>input_inferred_document_to_project</name>
                    <value>${output_document_to_project}</value>
                </property>
                <property>
                    <name>input_project_to_organization</name>
                    <value>${input_project_to_organization}</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${workingDir}/affiliation_matching_project_based/output</value>
                </property>
                <!-- FIXME either join the affmatch outcome or export to a different port! -->
                <property>
                    <name>project_fundingclass_whitelist_regex</name>
                    <value>${affiliationmatchingProjectFundingclassWhitelistRegex}</value>
                </property>
                <property>
                    <name>sparkExecutorMemory</name>
                    <value>${affiliationmatchingSparkExecutorMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorCores</name>
                    <value>${affiliationmatchingSparkExecutorCores}</value>
                </property>
                <property>
                    <name>sparkDriverMemory</name>
                    <value>${affiliationmatchingSparkDriverMemory}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="affiliation-matching-dedup" />
        <error to="fail" />
    </action>

    <action name="affiliation-matching-dedup">
        <sub-workflow>
            <app-path>${wf:appPath()}/affiliation_matching_dedup</app-path>
            <propagate-configuration />
            <configuration>
                <property>
                    <name>input_a</name>
                    <value>${workingDir}/affiliation_matching/output</value>
                </property>
                <property>
                    <name>input_b</name>
                    <value>${workingDir}/affiliation_matching_project_based/output</value>
                </property>
                 <property>
                    <name>inference_provenance_input_a</name>
                    <value>iis::document_referencedOrganizations_by_affiliation</value>
                </property>
                <property>
                    <name>inference_provenance_input_b</name>
                    <value>iis::document_referencedOrganizations_by_project</value>
                </property>
                <property>
                    <name>output</name>
                    <value>${output_matched_doc_organizations}</value>
                </property>
                <property>
                    <name>sparkExecutorMemory</name>
                    <value>${affiliationmatchingSparkExecutorMemory}</value>
                </property>
                <property>
                    <name>sparkExecutorCores</name>
                    <value>${affiliationmatchingSparkExecutorCores}</value>
                </property>
                <property>
                    <name>sparkDriverMemory</name>
                    <value>${affiliationmatchingSparkDriverMemory}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="report-execution-times" />
        <error to="fail" />
    </action>

    <action name="skip-affiliation-matching">
        <java>
            <prepare>
                <!-- notice: directory have to aligned with skipped action output -->
                <delete path="${nameNode}${output_matched_doc_organizations}" />
                <mkdir path="${nameNode}${output_matched_doc_organizations}" />
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.java.jsonworkflownodes.Producer</arg>
            <arg>-C{affmatching,
                eu.dnetlib.iis.wf.affmatching.model.MatchedOrganization,
                eu/dnetlib/iis/common/data/empty.json}
            </arg>
            <!-- notice: directory have to aligned with skipped action output -->
            <arg>-Oaffmatching=${output_matched_doc_organizations}</arg>
        </java>
        <ok to="report-execution-times" />
        <error to="fail" />
    </action>

	<action name="report-execution-times">
        <java>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.common.report.OozieTimeReportGenerator</arg>
            <arg>-PjobId=${wf:id()}</arg>
            <arg>-PoozieServiceLoc=${oozieServiceLoc}</arg>
            <arg>-Preport.processing.docOrgMatching.affiliationBased.duration=affiliation-matching</arg>
            <arg>-Preport.processing.docOrgMatching.projectBased.duration=affiliation-matching-project-based</arg>
            <arg>-Preport.processing.docOrgMatching.duration=affiliation-matching,affiliation-matching-project-based,affiliation-matching-dedup</arg>
            <arg>-Preport.processing.documentSimilarity.duration=transformers_documentssimilarity,documentssimilarity_chain</arg>
            <arg>-Preport.processing.citationMatching.direct.duration=citationmatching_direct</arg>
            <arg>-Preport.processing.citationMatching.fuzzy.duration=citationmatching_fuzzy</arg>
            <arg>-Preport.processing.citationMatching.duration=citationmatching_fuzzy,citationmatching_direct,transformers_citations_from_referencemetadata,citations_union</arg>
            <arg>-Preport.processing.citationTextExtraction.duration=citations_collapser,transformers_export_citations</arg>
            <arg>-Preport.processing.documentClassification.duration=documentsclassification</arg>
            <arg>-Preport.processing.referenceExtraction.researchInitiative.duration=referenceextraction_researchinitiative,referenceextraction_researchinitiative_wos,transformers_union_researchinitiatives,transformers_export_researchinitiatives</arg>
            <arg>-Preport.processing.referenceExtraction.community.duration=referenceextraction_community,transformers_export_communities</arg>
            <arg>-Preport.processing.referenceExtraction.covid-19.duration=referenceextraction_covid19,transformers_export_covid19</arg>
            <arg>-Preport.processing.referenceExtraction.service.duration=referenceextraction_service</arg>
            <arg>-Preport.processing.referenceExtraction.softwareUrl.duration=referenceextraction_software_url</arg>
            <arg>-Preport.processing.referenceExtraction.patent.duration=referenceextraction_patent</arg>
            <arg>-Preport.processing.referenceExtraction.pdb.duration=referenceextraction_pdb,transformers_export_pdb</arg>
            <arg>-Preport.processing.referenceExtraction.dataset.duration=referenceextraction_dataset</arg>
            <arg>-Preport.processing.referenceExtraction.project.duration=transformers_project_filter,referenceextraction_project</arg>
            <arg>-Preport.processing.merging.duration=transformers_common_union_document_text</arg>
            <arg>-Oreport=${output_report_root_path}/primary-processing-execution-times</arg>
        </java>
        <ok to="primary_processing_push_reports" />
        <error to="fail" />
    </action>

    <action name="primary_processing_push_reports">
        <sub-workflow>
            <app-path>${wf:appPath()}/push_reports</app-path>
            <propagate-configuration/>
            <configuration>
                <property>
                    <name>reports_dir_path</name>
                    <value>${output_report_root_path}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="end"/>
        <error to="fail"/>
    </action>

    <kill name="fail">
        <message>Unfortunately, the process failed -- error message:
            [${wf:errorMessage(wf:lastErrorNode())}]
        </message>
    </kill>
    <end name="end" />
</workflow-app>
